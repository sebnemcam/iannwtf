{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784) (32, 784) (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 15:24:15.970500: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-11-28 15:24:15.972477: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "# 1. get mnist from tensorflow_datasets\n",
    "mnist = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True)\n",
    "train_ds = mnist[0]\n",
    "val_ds = mnist[1]\n",
    "\n",
    "# 2. write function to create the dataset that we want\n",
    "def preprocess(data, batch_size, type):\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
    "    # image should be flattened\n",
    "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
    "    # we want to have two mnist images in each example\n",
    "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
    "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), data.shuffle(2000)))\n",
    "\n",
    "    if type == 'greater_equal':\n",
    "        # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *boolean\n",
    "        zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] + x2[1] >= 5))\n",
    "        # transform boolean target to int\n",
    "        zipped_ds = zipped_ds.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
    "        # batch the dataset\n",
    "        zipped_ds = zipped_ds.batch(batch_size)\n",
    "        # prefetch\n",
    "        zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    elif type == 'subtract':\n",
    "        # map ((x1,y1),(x2,y2)) to (x1,x2, y1 - y2)\n",
    "        #zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], abs(x1[1] - x2[1])))\n",
    "        zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] - x2[1]))\n",
    "        # batch the dataset\n",
    "        zipped_ds = zipped_ds.batch(batch_size)\n",
    "        # prefetch\n",
    "        zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return zipped_ds\n",
    "\n",
    "greater_equal_train_ds = preprocess(train_ds, batch_size=32, type='greater_equal')\n",
    "greater_equal_val_ds = preprocess(val_ds, batch_size=32, type=\"greater_equal\")\n",
    "\n",
    "subtract_train_ds = preprocess(train_ds, batch_size=32, type='subtract') #train_ds.apply(preprocess)\n",
    "subtract_val_ds = preprocess(val_ds, batch_size=32, type=\"subtract\") \n",
    "\n",
    "for img1, img2, label in greater_equal_train_ds.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwinMNISTModel(tf.keras.Model):\n",
    "\n",
    "    # 1. constructor\n",
    "    def __init__(self, type):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.metrics_list = [tf.keras.metrics.BinaryAccuracy(),\n",
    "                             tf.keras.metrics.Mean(name=\"loss\")]\n",
    "                \n",
    "        #type-dependent settings\n",
    "        if type == \"greater_equal\":\n",
    "            self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "            self.out_layer = tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)\n",
    "        elif type == \"subtract\":\n",
    "            self.loss_function = tf.keras.losses.MeanSquaredError()\n",
    "            self.out_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "        #same layers for both types\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(32, activation=tf.nn.relu)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # 2. call method (forward computation)\n",
    "    def call(self, images, training=False):\n",
    "        img1, img2 = images\n",
    "        \n",
    "        img1_x = self.dense1(img1)\n",
    "        img1_x = self.dense2(img1_x)\n",
    "        \n",
    "        img2_x = self.dense1(img2)\n",
    "        img2_x = self.dense2(img2_x)\n",
    "        \n",
    "        combined_x = tf.concat([img1_x, img2_x], axis=1)\n",
    "        \n",
    "        return self.out_layer(combined_x)\n",
    "\n",
    "\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "\n",
    "\n",
    "    # 5. train step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update the state of the metrics according to loss\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dictionary with metric names as keys and metric results as values\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "    \n",
    "    # 6. test_step method\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        # same as train step (without parameter updates)\n",
    "        output = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, output)\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writers(config_name):\n",
    "    \n",
    "    # Define where to save the logs\n",
    "    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n",
    "    # alternatively make a copy of the code that is used for later reference\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "    val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "    # log writer for validation metrics\n",
    "    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "    \n",
    "    return train_summary_writer, val_summary_writer\n",
    "\n",
    "train_summary_writer, val_summary_writer = create_summary_writers(config_name=\"RUN1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def train_model(type, optimizer):\n",
    "    #1. create model\n",
    "    model = TwinMNISTModel(type)\n",
    "    model.optimizer = optimizer\n",
    "\n",
    "    #2. create dataset\n",
    "    mnist = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True)\n",
    "    train_ds = mnist[0]\n",
    "    val_ds = mnist[1]\n",
    "    train_ds = preprocess(train_ds, batch_size=32, type=type)\n",
    "    val_ds = preprocess(val_ds, batch_size=32, type=type)\n",
    "\n",
    "    # 3. training loop\n",
    "    start_epoch = 0\n",
    "    epochs = 30\n",
    "    for e in range(start_epoch, epochs):\n",
    "\n",
    "        # 1. train steps on all batches in the training data\n",
    "        for data in tqdm.tqdm(train_ds, position=0, leave=True):\n",
    "            metrics = model.train_step(data)\n",
    "\n",
    "        # 2. log and print training metrics\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "        \n",
    "        #print the metrics\n",
    "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        \n",
    "        # 3. reset metric objects\n",
    "        model.reset_metrics()\n",
    "\n",
    "\n",
    "        # 4. evaluate on validation data\n",
    "        for data in val_ds:\n",
    "            metrics = model.test_step(data)\n",
    "        \n",
    "\n",
    "        # 5. log validation metrics\n",
    "\n",
    "        with val_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "            \n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        # 6. reset metric objects\n",
    "        model.reset_metrics()\n",
    "\n",
    "    # 7. save model weights if save_path is given\n",
    "    save_path = \"test-speicher\"\n",
    "    if save_path:\n",
    "        model.save_weights(save_path)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e3f725d1495d2156\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e3f725d1495d2156\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open the tensorboard logs\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible types\n",
    "    \"greater_equal\"\n",
    "    \"subtract\"\n",
    "\n",
    "Possible optimizers\n",
    "    tf.keras.optimizers.Adam()\n",
    "    tf.keras.optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:05<00:00, 371.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.11953333020210266', 'loss: 3.7735795974731445']\n",
      "['val_binary_accuracy: 0.12950000166893005', 'val_loss: 2.3355093002319336']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 484.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.13093332946300507', 'loss: 2.1583542823791504']\n",
      "['val_binary_accuracy: 0.1316000074148178', 'val_loss: 1.9378808736801147']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 501.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.13783332705497742', 'loss: 1.8315470218658447']\n",
      "['val_binary_accuracy: 0.14270000159740448', 'val_loss: 1.7500616312026978']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 562.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1394166648387909', 'loss: 1.6436582803726196']\n",
      "['val_binary_accuracy: 0.14059999585151672', 'val_loss: 1.7341139316558838']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 579.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.14104999601840973', 'loss: 1.534754991531372']\n",
      "['val_binary_accuracy: 0.14059999585151672', 'val_loss: 1.5739374160766602']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 573.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.13983333110809326', 'loss: 1.4474979639053345']\n",
      "['val_binary_accuracy: 0.14229999482631683', 'val_loss: 1.5402039289474487']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 580.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1423500031232834', 'loss: 1.3694908618927002']\n",
      "['val_binary_accuracy: 0.14569999277591705', 'val_loss: 1.5085698366165161']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 513.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1426166594028473', 'loss: 1.3092228174209595']\n",
      "['val_binary_accuracy: 0.14069999754428864', 'val_loss: 1.5767685174942017']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 551.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.14348334074020386', 'loss: 1.2463176250457764']\n",
      "['val_binary_accuracy: 0.147599995136261', 'val_loss: 1.4491242170333862']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 587.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1446666717529297', 'loss: 1.2092443704605103']\n",
      "['val_binary_accuracy: 0.1467999964952469', 'val_loss: 1.4348481893539429']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 515.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.14641666412353516', 'loss: 1.1727663278579712']\n",
      "['val_binary_accuracy: 0.1453000009059906', 'val_loss: 1.3890846967697144']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 494.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.14641666412353516', 'loss: 1.1379125118255615']\n",
      "['val_binary_accuracy: 0.13840000331401825', 'val_loss: 1.5018763542175293']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:04<00:00, 453.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.14785000681877136', 'loss: 1.1070386171340942']\n",
      "['val_binary_accuracy: 0.15199999511241913', 'val_loss: 1.4117687940597534']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 522.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.14710000157356262', 'loss: 1.0678279399871826']\n",
      "['val_binary_accuracy: 0.14409999549388885', 'val_loss: 1.334977626800537']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 512.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.14880000054836273', 'loss: 1.0757677555084229']\n",
      "['val_binary_accuracy: 0.15219999849796295', 'val_loss: 1.3230575323104858']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:05<00:00, 361.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.148416668176651', 'loss: 1.0302684307098389']\n",
      "['val_binary_accuracy: 0.1599999964237213', 'val_loss: 1.408939242362976']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 547.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1525166630744934', 'loss: 1.0013231039047241']\n",
      "['val_binary_accuracy: 0.14920000731945038', 'val_loss: 1.4005138874053955']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 544.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1526000052690506', 'loss: 0.9868374466896057']\n",
      "['val_binary_accuracy: 0.15129999816417694', 'val_loss: 1.3658167123794556']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 549.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15336667001247406', 'loss: 0.9679520130157471']\n",
      "['val_binary_accuracy: 0.1535000056028366', 'val_loss: 1.259988784790039']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 550.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1509000062942505', 'loss: 0.9547527432441711']\n",
      "['val_binary_accuracy: 0.15000000596046448', 'val_loss: 1.3599681854248047']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 554.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15504999458789825', 'loss: 0.9317067265510559']\n",
      "['val_binary_accuracy: 0.1500999927520752', 'val_loss: 1.3787431716918945']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 527.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1537666618824005', 'loss: 0.9239733219146729']\n",
      "['val_binary_accuracy: 0.14900000393390656', 'val_loss: 1.308957815170288']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 551.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15158332884311676', 'loss: 0.9116506576538086']\n",
      "['val_binary_accuracy: 0.14159999787807465', 'val_loss: 1.3555996417999268']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 497.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1516333371400833', 'loss: 0.8861414194107056']\n",
      "['val_binary_accuracy: 0.1509000062942505', 'val_loss: 1.2649399042129517']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 541.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15168333053588867', 'loss: 0.8802497982978821']\n",
      "['val_binary_accuracy: 0.14630000293254852', 'val_loss: 1.2794545888900757']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 498.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.1527666598558426', 'loss: 0.8758882284164429']\n",
      "['val_binary_accuracy: 0.1459999978542328', 'val_loss: 1.2820228338241577']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15494999289512634', 'loss: 0.8568170070648193']\n",
      "['val_binary_accuracy: 0.15119999647140503', 'val_loss: 1.2820227146148682']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 481.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15584999322891235', 'loss: 0.8492461442947388']\n",
      "['val_binary_accuracy: 0.15489999949932098', 'val_loss: 1.2210263013839722']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 512.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15205000340938568', 'loss: 0.8340210914611816']\n",
      "['val_binary_accuracy: 0.1412000060081482', 'val_loss: 1.371034860610962']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:03<00:00, 484.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_accuracy: 0.15209999680519104', 'loss: 0.828899621963501']\n",
      "['val_binary_accuracy: 0.14880000054836273', 'val_loss: 1.4175634384155273']\n"
     ]
    }
   ],
   "source": [
    "train_model(\"subtract\", tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greater_equal, Adam\n",
    "    nach 10 Epochen:\n",
    "        ['binary_accuracy: 0.9675999879837036', 'loss: 0.09635035693645477']\n",
    "        ['val_binary_accuracy: 0.9659000039100647', 'val_loss: 0.10654401779174805']\n",
    "\n",
    "greater_equal, SGD\n",
    "    nach 10 Epochen:\n",
    "        ['binary_accuracy: 0.9610000252723694', 'loss: 0.10990440100431442']\n",
    "        ['val_binary_accuracy: 0.9629999995231628', 'val_loss: 0.10369819402694702']\n",
    "\n",
    "subtract, Adam\n",
    "    nach 10 Epochen:\n",
    "        loss: 0.828899621963501\n",
    "        val_loss: 1.4175634384155273\n",
    "\n",
    "subtract, SGD\n",
    "    nach 30 Epochen:\n",
    "        loss: 1.0312447547912598\n",
    "        val_loss: 1.4527225494384766"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ed48ea506cc6e3e556dd6397f80ebb7e16428b1b3cf2350b34407ef5f1d989a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
